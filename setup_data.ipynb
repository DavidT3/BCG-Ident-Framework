{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ffef524-0c52-4f0e-bbb9-e8fe28efef7a",
   "metadata": {},
   "source": [
    "# Setting up for BCG identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6f7e9-0765-4fb4-bd07-c5a534aec00e",
   "metadata": {},
   "source": [
    "If you're a student working on a BCG identification project, there is no need for you to run this notebook!\n",
    "\n",
    "You're welcome to read through and get a handle on what the setup processes are doing though - the point of this notebook is essentially to make sure that all optical, infrared, and X-ray images are generated/downloaded ready for you to look at. The 'spot the BCG' notebook (the first of the set) will explain everything you need to know about those different wavelengths, and what we use them for.\n",
    "\n",
    "**If you're running this to setup a BCG identification run, make sure to go and configure everything in 'common.py' before running!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d930d1d-c71f-4681-b6c3-10be0b8695de",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bddffd0-5ada-4ad5-854b-068066985ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ident_run_setup import cosmo, rel_miss, rel_downloaders, side_length, init_samp_file, HISTORY_FILE_PATH, \\\n",
    "    HISTORY_ROOT, load_history, proj_name, update_history\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from astropy.units import Quantity\n",
    "import os\n",
    "from warnings import warn\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "try:\n",
    "    from xga.sourcetools import ang_to_rad\n",
    "    from xga.imagetools.misc import pix_deg_scale\n",
    "except:\n",
    "    # Using a general 'except' clause is not usually recommended - you ideally want to be catching\n",
    "    #  specific TYPES of error, so would specify them after the 'except' clause\n",
    "    raise ValueError(\"There was a problem importing XGA - likely running with a pre-multi-mission version.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4108b-3e7a-4ba4-adb2-b44144ccccfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e94001d-0408-4aef-a5c2-58a1928c40c7",
   "metadata": {},
   "source": [
    "## What cosmology is set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc2efd8-3a6c-41ab-a962-4ea8b36f0227",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55784a3-ea71-4dbb-ab96-0b81d7565062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LambdaCDM(name=None, H0=<Quantity 70. km / (Mpc s)>, Om0=0.3, Ode0=0.7, Tcmb0=<Quantity 0. K>, Neff=3.04, m_nu=None, Ob0=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d736c93c-9bd7-402b-a31f-3e5ac7a5ed61",
   "metadata": {},
   "source": [
    "## Loading and setting up the sample of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195c4d5a-bb7d-4c3d-802b-a9b904a03b02",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aef468c9-a5e5-45a5-a42f-c3b11e3209f3",
   "metadata": {},
   "source": [
    "### Reading in the sample file and checking for required information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21154f3-6915-4576-9bec-cd700cd77300",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf638c56-5dbe-4686-a076-ddda7ad88137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cent_im_ra</th>\n",
       "      <th>cent_im_dec</th>\n",
       "      <th>redshift</th>\n",
       "      <th>r500</th>\n",
       "      <th>r500-</th>\n",
       "      <th>r500+</th>\n",
       "      <th>r2500</th>\n",
       "      <th>r2500-</th>\n",
       "      <th>r2500+</th>\n",
       "      <th>XCS_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SDSSXCS-124</td>\n",
       "      <td>0.800578</td>\n",
       "      <td>-6.091818</td>\n",
       "      <td>0.247483</td>\n",
       "      <td>1181.028159</td>\n",
       "      <td>21.202221</td>\n",
       "      <td>23.202641</td>\n",
       "      <td>534.834740</td>\n",
       "      <td>7.579124</td>\n",
       "      <td>7.591855</td>\n",
       "      <td>XMMXCS J000312.1-060530.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDSSXCS-2789</td>\n",
       "      <td>0.955540</td>\n",
       "      <td>2.068019</td>\n",
       "      <td>0.105285</td>\n",
       "      <td>1007.860978</td>\n",
       "      <td>17.194150</td>\n",
       "      <td>17.201505</td>\n",
       "      <td>438.706515</td>\n",
       "      <td>5.198301</td>\n",
       "      <td>5.213676</td>\n",
       "      <td>XMMXCS J000349.3+020404.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDSSXCS-290</td>\n",
       "      <td>2.722639</td>\n",
       "      <td>29.161021</td>\n",
       "      <td>0.348495</td>\n",
       "      <td>913.052256</td>\n",
       "      <td>30.878754</td>\n",
       "      <td>31.209675</td>\n",
       "      <td>412.606577</td>\n",
       "      <td>11.014644</td>\n",
       "      <td>11.199164</td>\n",
       "      <td>XMMXCS J001053.4+290939.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDSSXCS-1018</td>\n",
       "      <td>4.406325</td>\n",
       "      <td>-0.876192</td>\n",
       "      <td>0.214403</td>\n",
       "      <td>902.259231</td>\n",
       "      <td>22.444665</td>\n",
       "      <td>23.366414</td>\n",
       "      <td>399.213342</td>\n",
       "      <td>6.774208</td>\n",
       "      <td>6.817562</td>\n",
       "      <td>XMMXCS J001737.5-005234.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SDSSXCS-134</td>\n",
       "      <td>4.908390</td>\n",
       "      <td>3.609818</td>\n",
       "      <td>0.277304</td>\n",
       "      <td>1123.320736</td>\n",
       "      <td>19.219312</td>\n",
       "      <td>19.225964</td>\n",
       "      <td>510.738163</td>\n",
       "      <td>8.475349</td>\n",
       "      <td>7.419581</td>\n",
       "      <td>XMMXCS J001938.0+033635.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  cent_im_ra  cent_im_dec  redshift         r500      r500-  \\\n",
       "0   SDSSXCS-124    0.800578    -6.091818  0.247483  1181.028159  21.202221   \n",
       "1  SDSSXCS-2789    0.955540     2.068019  0.105285  1007.860978  17.194150   \n",
       "2   SDSSXCS-290    2.722639    29.161021  0.348495   913.052256  30.878754   \n",
       "3  SDSSXCS-1018    4.406325    -0.876192  0.214403   902.259231  22.444665   \n",
       "4   SDSSXCS-134    4.908390     3.609818  0.277304  1123.320736  19.219312   \n",
       "\n",
       "       r500+       r2500     r2500-     r2500+                   XCS_NAME  \n",
       "0  23.202641  534.834740   7.579124   7.591855  XMMXCS J000312.1-060530.5  \n",
       "1  17.201505  438.706515   5.198301   5.213676  XMMXCS J000349.3+020404.8  \n",
       "2  31.209675  412.606577  11.014644  11.199164  XMMXCS J001053.4+290939.6  \n",
       "3  23.366414  399.213342   6.774208   6.817562  XMMXCS J001737.5-005234.2  \n",
       "4  19.225964  510.738163   8.475349   7.419581  XMMXCS J001938.0+033635.3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Point the notebook to the CSV containing basic information about the sample of clusters\n",
    "samp = pd.read_csv(init_samp_file)\n",
    "\n",
    "# A notebook isn't really the ideal environment for this, as each individual cell can be re-run, changing what is stored in \n",
    "#  memory (RAM). As such, we'll run the checks for specific column names in the same cell in which we read in the sample file, so \n",
    "#  no other cell has a chance to modify the dataframe\n",
    "if (~np.isin(np.array(['name', 'cent_im_ra', 'cent_im_dec', 'redshift']), samp.columns)).any():\n",
    "    col_names = \", \".join(samp.columns)\n",
    "    raise KeyError(\"Some required sample columns are not present; input file columns are - {}.\".format(col_names))\n",
    "\n",
    "# Show a snippet of the sample as a quick check, though it must have the required columns to have reached this point\n",
    "samp.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d884781-b361-413a-a1ea-554a8634683e",
   "metadata": {},
   "source": [
    "### Adding angular-to-proper distance ratios to sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d8d28-fad0-444a-955a-d2429443557b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af59206-affc-4710-ab6e-382e70dd65c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$[232.85997,~115.803,~295.55704,~\\dots,~267.60965,~240.999,~244.77679] \\; \\mathrm{\\frac{kpc}{{}^{\\prime}}}$"
      ],
      "text/plain": [
       "<Quantity [232.85996665, 115.80299749, 295.55703817, 208.96598069,\n",
       "           252.89890756, 269.81894828, 247.33755558, 114.52471534,\n",
       "           194.94231833, 170.37909225, 267.73456559, 243.03871063,\n",
       "           237.04613445, 250.97065817, 296.03651206, 218.71296151,\n",
       "           226.99764355, 139.9268915 , 162.36287491, 291.81585769,\n",
       "           293.38496704, 193.45924487, 263.67045471, 266.85508032,\n",
       "           279.93736808, 154.01150752, 159.03597111, 172.18417051,\n",
       "           196.33890555, 150.35262411, 215.1828343 , 292.29413403,\n",
       "           270.50009972, 189.55288372, 188.8036126 , 224.0695333 ,\n",
       "           182.51841177, 185.28558211, 162.42377759, 278.45876006,\n",
       "           223.99993875, 265.06180711, 196.64751522, 198.76749964,\n",
       "           111.08449251, 236.60234346, 237.22957694, 174.26959646,\n",
       "           218.20911517, 224.5003265 , 270.38729628, 263.68781889,\n",
       "           267.22414102, 186.1694538 , 226.32939904, 274.73269229,\n",
       "           281.46620208, 115.51995152, 201.97544287, 260.42878372,\n",
       "           262.114158  , 141.82193387, 150.79173236, 157.34032833,\n",
       "           204.56635018, 281.15452104, 220.95611625, 177.36144469,\n",
       "           186.15497752, 125.65991853, 288.0143438 , 171.74129531,\n",
       "           144.54190576, 149.0391954 , 288.48929481, 228.69011803,\n",
       "           189.88722767, 289.47283776, 269.68177627, 195.96270324,\n",
       "           185.3874474 , 219.09971269, 220.17128283, 214.24135648,\n",
       "           274.63026526, 219.18705851, 230.39935017, 116.80426346,\n",
       "           214.02788711, 277.10135221, 242.46185743, 276.80116033,\n",
       "           184.04606551, 174.25566036, 227.94329511, 262.37643311,\n",
       "           282.75542554, 182.9075696 , 202.62070953, 251.61378183,\n",
       "           261.60903961, 221.72024563, 162.86579866, 288.51510799,\n",
       "           239.46561591, 146.14403654, 225.74282643, 146.42232846,\n",
       "           274.67210774, 146.67530013, 174.31432454, 145.6960354 ,\n",
       "           168.1089996 , 115.6202246 , 259.06775649, 247.96146507,\n",
       "           165.34473272, 129.08134841, 112.78249789, 130.33630881,\n",
       "           121.14185338, 187.07703023, 270.5081083 , 223.22965457,\n",
       "           187.82599559, 217.83495608, 222.45265249, 234.51872211,\n",
       "           170.01057699, 219.96923594, 232.69207098, 287.37417448,\n",
       "           223.6925335 , 255.6830986 , 148.20031719, 235.00382679,\n",
       "           123.76461312, 240.48306651, 281.35816351, 178.39380503,\n",
       "           274.99144129, 272.18220302, 270.15748493, 267.69788861,\n",
       "           165.5272929 , 284.09466778, 276.31443875, 267.60965262,\n",
       "           240.99900302, 244.77679414] kpc / arcmin>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ang_step = Quantity(1, 'arcmin')\n",
    "ang_prop_ratios = (ang_to_rad(ang_step, samp['redshift'].values, cosmo=cosmo) / ang_step)\n",
    "# Unfortunately dataframes and quantities do not seem to be getting on at the moment, so we save the\n",
    "#  float version of these values\n",
    "samp['ang_prop_ratio'] = ang_prop_ratios.value\n",
    "ang_prop_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6016340-24b5-4099-bda8-b4dc5319d3a1",
   "metadata": {},
   "source": [
    "## Setting up directory structure and history files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21253f29-cb74-445d-b442-a8015f2c03b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b16d2350-95b3-46d3-9e43-8936b0adb972",
   "metadata": {},
   "source": [
    "### Storage for files that record the history of the identification run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2524f52-caef-44f7-93a0-84b502a7db16",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4ed3a3-27ac-4f64-b586-c95815ecf5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_samp_file = os.path.join(HISTORY_ROOT, 'STATIC_'+proj_name+'.csv')\n",
    "\n",
    "if os.path.exists(HISTORY_FILE_PATH):\n",
    "    cur_history = load_history()\n",
    "    samp = pd.read_csv(static_samp_file)\n",
    "    ang_prop_ratios = Quantity(samp['ang_prop_ratio'], 'kpc/arcmin')\n",
    "    \n",
    "else:\n",
    "    if not os.path.exists(HISTORY_ROOT):\n",
    "        os.makedirs(HISTORY_ROOT)\n",
    "    \n",
    "    if not os.path.exists(HISTORY_FILE_PATH):\n",
    "\n",
    "        clust_ops = {n: {'raw_images': {mn: {'complete': False} for mn in rel_miss}} for n in samp['name'].values}\n",
    "        \n",
    "        cur_history = {'project_name': proj_name,\n",
    "                       'num_clusters': len(samp),\n",
    "                       'static_samp_file': static_samp_file,\n",
    "                       'chosen_missions': rel_miss,\n",
    "                       'cosmo_repr': str(cosmo),\n",
    "                       'side_length': side_length.to('kpc').value,\n",
    "                       'data_operations': clust_ops}\n",
    "        \n",
    "        with open(HISTORY_FILE_PATH, 'w') as write_historo:\n",
    "            json.dump(cur_history, write_historo)\n",
    "        \n",
    "        samp.to_csv(static_samp_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d57acd6-eb31-4052-b5b3-ddd2c385508b",
   "metadata": {},
   "source": [
    "### Storage for downloaded/generated raw images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba5624-0d69-48b6-8c00-a149fb4ceaa1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36f94b0-f6d2-4fd4-bd1c-3f077616273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_im_pth = os.path.abspath(\"raw_images/{n}/{m}\") + '/'\n",
    "\n",
    "for src_name in samp['name'].values:\n",
    "    for miss_name in rel_miss:\n",
    "        if not os.path.exists(raw_im_pth.format(m=miss_name, n=src_name)):\n",
    "            os.makedirs(raw_im_pth.format(m=miss_name, n=src_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09875dc2-ec2f-42b2-ace6-e7ec30fad660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d37bb83-fdd6-43d0-99bc-6d1e2fb71bed",
   "metadata": {},
   "source": [
    "### Storage for outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a75f5-03f7-4e86-831f-46d9fd3fb567",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7431ef-75a3-4812-b558-790439f80a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f94fa3f0-e291-4198-9fb5-dc02af17b647",
   "metadata": {},
   "source": [
    "## Generating and saving XMM count-rate maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef584cef-b004-4a67-a866-9865e101ae3a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15ae5c89-e2db-49e2-a980-201624dd7aaa",
   "metadata": {},
   "source": [
    "## Downloading DESI Legacy Survey optical/NIR photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08e928-889b-4afd-be9b-19e4b5846a56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f503053f-50ba-4e69-abb0-a35435d64086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "ls_pixsize_lim = Quantity(3000, 'pix')\n",
    "\n",
    "#\n",
    "ls_start_pix_scale = Quantity(0.262, 'arcsec/pixel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8720e534-9a3d-4a34-be92-6904d8d53574",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a8c98d3-b102-4ecf-aa89-25872fccccf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dt237/software/anaconda3/envs/new_xga_dev/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: UserWarning: The Legacy Survey pixel side length for one or more clusters is greater than allowed by the cutout server - changing pixel scale to 0.524 arcsec / pix\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "Downloading DESI Legacy Survey DR10 photometry: 100%|█████████████████████| 150/150 [00:00<00:00, 8491.41it/s]\n"
     ]
    }
   ],
   "source": [
    "if 'desi-ls' in rel_miss:\n",
    "    # Setting up the downloader class instance\n",
    "    desi_down = rel_downloaders['desi-ls']()\n",
    "\n",
    "    ls_pix_side_lengths = ((side_length/ang_prop_ratios)/ls_start_pix_scale).to('pix')\n",
    "\n",
    "    if (ls_pix_side_lengths > ls_pixsize_lim).any():\n",
    "        ls_worst_pix_len = ls_pix_side_lengths.max()\n",
    "        ls_pix_scale_multi = np.ceil(ls_worst_pix_len / ls_pixsize_lim).astype(int)\n",
    "        warn(\"The Legacy Survey pixel side length for one or more clusters is greater than allowed by the cutout \" \\\n",
    "             \"server - changing pixel scale to {}\".format(ls_pix_scale_multi*ls_start_pix_scale), stacklevel=2)\n",
    "    else:\n",
    "        ls_pix_scale_multi = 1\n",
    "\n",
    "    # Set up the final pixel scale\n",
    "    ls_final_pix_scale = ls_start_pix_scale * ls_pix_scale_multi\n",
    "\n",
    "    # Recalculate with the final scale\n",
    "    ls_pix_side_lengths = ((side_length/ang_prop_ratios)/ls_final_pix_scale).to('pix')\n",
    "\n",
    "    # We make a copy of the data operations section of the history, as it may be changed in this next bit\n",
    "    data_op_hist = deepcopy(cur_history['data_operations'])\n",
    "    # And a change flag\n",
    "    hist_change = False\n",
    "    \n",
    "    # Iterating through dataframes like this is a bad idea if you're performing calculations on dataframe information, or if the\n",
    "    #  dataframe is large (more than a few thousand entries), as iterating is very slow. However, we're just iterating to read\n",
    "    #  things out, so it is sort of okay (and quite convenient)\n",
    "    with tqdm(total=len(samp), desc='Downloading DESI Legacy Survey DR10 photometry') as onwards:\n",
    "        for row_ind, row in samp.iterrows():\n",
    "            # Read out the cluster name - so we can store things in the right place, and keep track of which image\n",
    "            #  belongs to which cluster\n",
    "            cur_name = row['name']\n",
    "            \n",
    "            # First, lets check if this cluster has had DESI-LS data downloaded already. We'll use the project \n",
    "            #  history, as it is much computationally cheaper than checking if the expected file names exist\n",
    "            if cur_history['data_operations'][cur_name]['raw_images']['desi-ls']['complete']:\n",
    "                onwards.update(1)\n",
    "                continue\n",
    "\n",
    "            # Reading out relevant information - position is obviously very important, it is where we will center the\n",
    "            #  downloaded images\n",
    "            cur_ra = row['cent_im_ra']\n",
    "            cur_dec = row['cent_im_dec']\n",
    "            # The conversion between arcmin and arcminutes we calculated earlier, note that retrieving from a row\n",
    "            #  of a dataframe like this seems to render it a float again, rather than an Astropy quantity\n",
    "            cur_ang_prop_ratio = Quantity(row['ang_prop_ratio'], 'kpc/arcmin')\n",
    "\n",
    "    \n",
    "            # Though we already calculated the final pixel sizes we need for the LS images, the download method\n",
    "            #  wants the pixel scale and an angular side length specified seperately, so we have to convert the\n",
    "            #  proper side-length to degrees\n",
    "            cur_deg_side_length = (side_length / cur_ang_prop_ratio).to('deg')\n",
    "    \n",
    "            # Populate the raw image storage directory path, with the cluster name and the current mission name\n",
    "            cur_download_dir = raw_im_pth.format(n=cur_name, m='desi-ls')\n",
    "            # Set up the final raw image file name, with some useful info in it\n",
    "            cur_file_name = \"{n}_sidelength{sl}_pixscale{ps}.jpeg\".format(n=cur_name, sl=str(side_length).replace(' ', ''), \n",
    "                                                                          ps=str(ls_final_pix_scale).replace(' ', '').replace('/', 'per'))\n",
    "            # Combine the raw image storage path with the file name\n",
    "            cur_download_pth = os.path.join(cur_download_dir, cur_file_name)\n",
    "    \n",
    "            # desi_down.download(ra=cur_ra, dec=cur_dec, bands='griz', layer='ls-dr10', mode='jpeg', autoscale=False, \n",
    "            #                    ddir=cur_download_dir, size=cur_deg_side_length.value, pixscale=ls_final_pix_scale.value)\n",
    "    \n",
    "            # Change the name of the downloaded file to something more descriptive\n",
    "            down_file_name = 'legacystamps_{r}_{d}_ls-dr10.jpeg'.format(r='{:.6f}'.format(cur_ra), d='{:.6f}'.format(cur_dec))\n",
    "            down_file_path = os.path.join(cur_download_dir, down_file_name)\n",
    "            # os.rename(down_file_path, cur_download_pth)\n",
    "\n",
    "            # Now we add to the data operation history - as well as setting the change flag to True so we know to run the \n",
    "            #  history file update at the end of the looping\n",
    "            hist_change = True\n",
    "            data_op_hist[cur_name]['raw_images']['desi-ls']['complete'] = True\n",
    "            data_op_hist[cur_name]['raw_images']['desi-ls']['arcsec_per_pix'] = ls_final_pix_scale.value\n",
    "            # This shouldn't be necessary, as it should be setup so the sample content won't change, but we'll\n",
    "            #  save the central RA and Dec here as well, so all the WCS-related information will be in one place\n",
    "            data_op_hist[cur_name]['raw_images']['desi-ls']['cen_pos'] = [cur_ra, cur_dec]\n",
    "            data_op_hist[cur_name]['raw_images']['desi-ls']['im_path'] = cur_download_pth\n",
    "            \n",
    "            onwards.update(1)\n",
    "\n",
    "    # Only run the update history function if there were changes\n",
    "    if hist_change:\n",
    "        update_history({'data_operations': data_op_hist})\n",
    "\n",
    "# TODO COULD ADD SOME NICE FAIL SAFE SO THAT IT ATTEMPTS TO DOWNLOAD AN SDSS IMAGE IF THERE IS NO LS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9bcc5-28f6-4d4e-b7a5-c4353acb208c",
   "metadata": {},
   "source": [
    "## Downloading VLASS images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72d232-a93f-4968-884e-5a390259e0a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34f2204e-28de-44a0-97a5-d9c6b2a5806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading VLASS maps:   0%|                                                         | 0/150 [00:00<?, ?it/s][EveryStamp:VLASSDownloader] 2025-01-14 14:22:54,076 - INFO: Downloading cutout from VLASS\n",
      "[EveryStamp:VLASSDownloader] 2025-01-14 14:22:54,080 - WARNING: Could not find VLASS summary file VLASS_dyn_summary.php!\n",
      "[EveryStamp:VLASSDownloader] 2025-01-14 14:22:54,080 - INFO: Attempting to download VLASS summary file\n",
      "Downloading VLASS maps:   0%|                                                         | 0/150 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wget'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m cur_download_pth \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cur_download_dir, cur_file_name)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43mvlass_down\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_ra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_dec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_download_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcur_deg_side_length\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m stop\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Change the name of the downloaded file to something more descriptive\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/new_xga_dev/lib/python3.12/site-packages/everystamp/downloaders.py:706\u001b[0m, in \u001b[0;36mVLASSDownloader.download\u001b[0;34m(self, ra, dec, size, ms, crop, consider_QA_rejected, ddir)\u001b[0m\n\u001b[1;32m    704\u001b[0m crop_scale \u001b[38;5;241m=\u001b[39m size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3600\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpixel_scale\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading cutout from VLASS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_vlass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrop_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrop_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconsider_QA_rejected\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsider_QA_rejected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mddir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/new_xga_dev/lib/python3.12/site-packages/everystamp/downloaders.py:629\u001b[0m, in \u001b[0;36mVLASSDownloader.search_vlass\u001b[0;34m(self, c, crop, crop_scale, consider_QA_rejected, ddir)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;124;03mSearches the VLASS catalog for a source\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m    Name of the output image.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# Find the VLASS tile\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m tiles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m tilename, epoch, obsdate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_tiles(tiles, c)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatatype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# No other epoch available for now, so hardcode until the code is updated.\u001b[39;00m\n",
      "File \u001b[0;32m~/software/anaconda3/envs/new_xga_dev/lib/python3.12/site-packages/everystamp/downloaders.py:380\u001b[0m, in \u001b[0;36mVLASSDownloader.get_tiles\u001b[0;34m(self, summary_file)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find VLASS summary file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to download VLASS summary file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 380\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://archive-new.nrao.edu/vlass/VLASS_dyn_summary.php\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-O\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m            \u001b[49m\u001b[43msummary_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# Put it in a more managable format by replacing consecutive white space with commas.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Assumes no more than 1 space in valid entries.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m subprocess\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-e\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms/ \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m2,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m}/,/g\u001b[39m\u001b[38;5;124m\"\u001b[39m, summary_file], check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/new_xga_dev/lib/python3.12/subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/software/anaconda3/envs/new_xga_dev/lib/python3.12/subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/software/anaconda3/envs/new_xga_dev/lib/python3.12/subprocess.py:1955\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1955\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wget'"
     ]
    }
   ],
   "source": [
    "if 'vlass' in rel_miss:\n",
    "    # Setting up the downloader class instance for VLASS - it has fewer download options than the DESI one does\n",
    "    vlass_down = rel_downloaders['vlass']()\n",
    "\n",
    "    # We make a copy of the data operations section of the history, as it may be changed in this next bit\n",
    "    data_op_hist = deepcopy(cur_history['data_operations'])\n",
    "    # And a change flag\n",
    "    hist_change = False\n",
    "    \n",
    "    # Iterating through dataframes like this is a bad idea if you're performing calculations on dataframe information, or if the\n",
    "    #  dataframe is large (more than a few thousand entries), as iterating is very slow. However, we're just iterating to read\n",
    "    #  things out, so it is sort of okay (and quite convenient)\n",
    "    with tqdm(total=len(samp), desc='Downloading VLASS maps') as onwards:\n",
    "        for row_ind, row in samp.iterrows():\n",
    "            # Read out the cluster name - so we can store things in the right place, and keep track of which image\n",
    "            #  belongs to which cluster\n",
    "            cur_name = row['name']\n",
    "            \n",
    "            # First, lets check if this cluster has had VLASS maps downloaded already. We'll use the project \n",
    "            #  history, as it is much computationally cheaper than checking if the expected file names exist\n",
    "            if cur_history['data_operations'][cur_name]['raw_images']['vlass']['complete']:\n",
    "                onwards.update(1)\n",
    "                continue\n",
    "\n",
    "            # Reading out relevant information - position is obviously very important, it is where we will center the\n",
    "            #  downloaded images\n",
    "            cur_ra = row['cent_im_ra']\n",
    "            cur_dec = row['cent_im_dec']\n",
    "            # The conversion between arcmin and arcminutes we calculated earlier, note that retrieving from a row\n",
    "            #  of a dataframe like this seems to render it a float again, rather than an Astropy quantity\n",
    "            cur_ang_prop_ratio = Quantity(row['ang_prop_ratio'], 'kpc/arcmin')\n",
    "\n",
    "    \n",
    "            # Though we already calculated the final pixel sizes we need for the LS images, the download method\n",
    "            #  wants the pixel scale and an angular side length specified seperately, so we have to convert the\n",
    "            #  proper side-length to degrees\n",
    "            cur_deg_side_length = (side_length / cur_ang_prop_ratio).to('deg')\n",
    "    \n",
    "            # Populate the raw image storage directory path, with the cluster name and the current mission name\n",
    "            cur_download_dir = raw_im_pth.format(n=cur_name, m='vlass')\n",
    "            # Set up the final raw image file name, with some useful info in it\n",
    "            cur_file_name = \"{n}_sidelength{sl}_pixscale{ps}.fits\".format(n=cur_name, sl=str(side_length).replace(' ', ''), \n",
    "                                                                          ps='2.5arcsecperpix')\n",
    "            # Combine the raw image storage path with the file name\n",
    "            cur_download_pth = os.path.join(cur_download_dir, cur_file_name)\n",
    "\n",
    "            #\n",
    "            vlass_down.download(ra=cur_ra, dec=cur_dec, ddir=cur_download_dir, size=cur_deg_side_length.value)\n",
    "            stop\n",
    "            # Change the name of the downloaded file to something more descriptive\n",
    "            down_file_name = 'legacystamps_{r}_{d}_ls-dr10.jpeg'.format(r='{:.6f}'.format(cur_ra), d='{:.6f}'.format(cur_dec))\n",
    "            down_file_path = os.path.join(cur_download_dir, down_file_name)\n",
    "            # os.rename(down_file_path, cur_download_pth)\n",
    "\n",
    "            # Now we add to the data operation history - as well as setting the change flag to True so we know to run the \n",
    "            #  history file update at the end of the looping\n",
    "            hist_change = True\n",
    "            data_op_hist[cur_name]['raw_images']['desi-ls']['complete'] = True\n",
    "            data_op_hist[cur_name]['raw_images']['desi-ls']['arcsec_per_pix'] = ls_final_pix_scale.value\n",
    "            # This shouldn't be necessary, as it should be setup so the sample content won't change, but we'll\n",
    "            #  save the central RA and Dec here as well, so all the WCS-related information will be in one place\n",
    "            data_op_hist[cur_name]['raw_images']['desi-ls']['cen_pos'] = [cur_ra, cur_dec]\n",
    "            data_op_hist[cur_name]['raw_images']['desi-ls']['im_path'] = cur_download_pth\n",
    "            \n",
    "            onwards.update(1)\n",
    "\n",
    "    # Only run the update history function if there were changes\n",
    "    if hist_change:\n",
    "        update_history({'data_operations': data_op_hist})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e7d9577-d03f-4d01-bd3a-da5b12ed62ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method download in module everystamp.downloaders:\n",
      "\n",
      "download(ra=0.0, dec=0.0, size=0.1, ms='', crop=True, consider_QA_rejected=False, ddir='/Users/dt237/projects/BCG-Identification-Framework') method of everystamp.downloaders.VLASSDownloader instance\n",
      "    Download a cutout from the VLASS survey.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    ra : float\n",
      "        Right ascension of the coordinate of interest.\n",
      "    dec : float\n",
      "        Declination of the coordinate of interest.\n",
      "    size : float\n",
      "        Size of the area of interest in degrees.\n",
      "    ms : str\n",
      "        Path to a Measurement Set to take coordinates from instead of using ra and dec.\n",
      "    crop : bool\n",
      "        Crop the image to the area of interest.\n",
      "    consider_QA_rejected : bool\n",
      "        Also consider tiles that failed the Quality Assurance checks.\n",
      "    ddir : str\n",
      "        Location to download the cutout to.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vlass_down.download)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
